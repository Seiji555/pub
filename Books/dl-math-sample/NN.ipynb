{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "誤差 =  69.7705 ( 1000エポック目)\n",
      "誤差 =  55.0522 ( 2000エポック目)\n",
      "誤差 =  44.4299 ( 3000エポック目)\n",
      "誤差 =  24.9272 ( 4000エポック目)\n",
      "誤差 =  15.0983 ( 5000エポック目)\n",
      "誤差 =  11.5577 ( 6000エポック目)\n",
      "誤差 =   9.6375 ( 7000エポック目)\n",
      "誤差 =   8.4023 ( 8000エポック目)\n",
      "誤差 =   7.5279 ( 9000エポック目)\n",
      "誤差 =   6.8681 (10000エポック目)\n",
      "誤差 =   6.3472 (11000エポック目)\n",
      "誤差 =   5.9225 (12000エポック目)\n",
      "誤差 =   5.5672 (13000エポック目)\n",
      "誤差 =   5.2649 (14000エポック目)\n",
      "誤差 =   5.0039 (15000エポック目)\n",
      "誤差 =   4.7761 (16000エポック目)\n",
      "誤差 =   4.5755 (17000エポック目)\n",
      "誤差 =   4.3975 (18000エポック目)\n",
      "誤差 =   4.2384 (19000エポック目)\n",
      "誤差 =   4.0956 (20000エポック目)\n",
      "誤差 =   3.9667 (21000エポック目)\n",
      "誤差 =   3.8496 (22000エポック目)\n",
      "誤差 =   3.7430 (23000エポック目)\n",
      "誤差 =   3.6453 (24000エポック目)\n",
      "誤差 =   3.5555 (25000エポック目)\n",
      "誤差 =   3.4725 (26000エポック目)\n",
      "誤差 =   3.3955 (27000エポック目)\n",
      "誤差 =   3.3238 (28000エポック目)\n",
      "誤差 =   3.2566 (29000エポック目)\n",
      "誤差 =   3.1936 (30000エポック目)\n",
      "精度: 98.4%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 学習データの数\n",
    "N = 1000\n",
    "\n",
    "# (学習に再現性をもたせるために シードを固定しています。本来は不要です)\n",
    "np.random.seed(1)\n",
    "\n",
    "# 適当な学習データと正解ラベルを生成\n",
    "TX = (np.random.rand(N, 2) * 1000).astype(np.int32) + 1\n",
    "TY = (TX.min(axis=1) / TX.max(axis=1) <= 0.2).astype(np.int)[np.newaxis].T\n",
    "\n",
    "# 平均と標準偏差を計算\n",
    "MU = TX.mean(axis=0)\n",
    "SIGMA = TX.std(axis=0)\n",
    "\n",
    "# 標準化\n",
    "def standardize(X):\n",
    "    return (X - MU) / SIGMA\n",
    "\n",
    "TX = standardize(TX)\n",
    "\n",
    "# 重みとバイアス\n",
    "W1 = np.random.randn(2, 2) # 第1層重み\n",
    "W2 = np.random.randn(2, 2) # 第2層重み\n",
    "W3 = np.random.randn(1, 2) # 第3層重み\n",
    "b1 = np.random.randn(2)    # 第1層バイアス\n",
    "b2 = np.random.randn(2)    # 第2層バイアス\n",
    "b3 = np.random.randn(1)    # 第3層バイアス\n",
    "\n",
    "# シグモイド関数\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "# 順伝播\n",
    "def forward(X0):\n",
    "    Z1 = np.dot(X0, W1.T) + b1\n",
    "    X1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(X1, W2.T) + b2\n",
    "    X2 = sigmoid(Z2)\n",
    "    Z3 = np.dot(X2, W3.T) + b3\n",
    "    X3 = sigmoid(Z3)\n",
    "\n",
    "    return Z1, X1, Z2, X2, Z3, X3\n",
    "\n",
    "# シグモイド関数の微分\n",
    "def dsigmoid(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)\n",
    "\n",
    "# 出力層のデルタ\n",
    "def delta_output(Z, Y):\n",
    "    return (sigmoid(Z) - Y) * dsigmoid(Z)\n",
    "\n",
    "# 隠れ層のデルタ\n",
    "def delta_hidden(Z, D, W):\n",
    "    return dsigmoid(Z) * np.dot(D, W)\n",
    "\n",
    "# 逆伝播\n",
    "def backward(Y, Z3, Z2, Z1):\n",
    "    D3 = delta_output(Z3, Y)\n",
    "    D2 = delta_hidden(Z2, D3, W3)\n",
    "    D1 = delta_hidden(Z1, D2, W2)\n",
    "\n",
    "    return D3, D2, D1\n",
    "\n",
    "# 学習率\n",
    "ETA = 0.001\n",
    "\n",
    "# 目的関数の重みでの微分\n",
    "def dweight(D, X):\n",
    "    return np.dot(D.T, X)\n",
    "\n",
    "# 目的関数のバイアスでの微分\n",
    "def dbias(D):\n",
    "    return D.sum(axis=0)\n",
    "\n",
    "# パラメータの更新\n",
    "def update_parameters(D3, X2, D2, X1, D1, X0):\n",
    "    global W3, W2, W1, b3, b2, b1\n",
    "\n",
    "    W3 = W3 - ETA * dweight(D3, X2)\n",
    "    W2 = W2 - ETA * dweight(D2, X1)\n",
    "    W1 = W1 - ETA * dweight(D1, X0)\n",
    "\n",
    "    b3 = b3 - ETA * dbias(D3)\n",
    "    b2 = b2 - ETA * dbias(D2)\n",
    "    b1 = b1 - ETA * dbias(D1)\n",
    "\n",
    "# 学習\n",
    "def train(X, Y):\n",
    "    # 順伝播\n",
    "    Z1, X1, Z2, X2, Z3, X3 = forward(X)\n",
    "\n",
    "    # 逆伝播\n",
    "    D3, D2, D1 = backward(Y, Z3, Z2, Z1)\n",
    "\n",
    "    # パラメータの更新\n",
    "    update_parameters(D3, X2, D2, X1, D1, X)\n",
    "\n",
    "# 繰り返し回数\n",
    "EPOCH = 30000\n",
    "\n",
    "# 予測\n",
    "def predict(X):\n",
    "    return forward(X)[-1]\n",
    "\n",
    "# 目的関数\n",
    "def E(Y, X):\n",
    "    return 0.5 * ((Y - predict(X)) ** 2).sum()\n",
    "\n",
    "# ミニバッチ数\n",
    "BATCH = 100\n",
    "\n",
    "for epoch in range(1, EPOCH + 1):\n",
    "    # ミニバッチ学習用にランダムなインデックスを取得\n",
    "    p = np.random.permutation(len(TX))\n",
    "\n",
    "    # ミニバッチの数分だけデータを取り出して学習\n",
    "    for i in range(math.ceil(len(TX) / BATCH)):\n",
    "        indice = p[i*BATCH:(i+1)*BATCH]\n",
    "        X0 = TX[indice]\n",
    "        Y  = TY[indice]\n",
    "\n",
    "        train(X0, Y)\n",
    "\n",
    "    # ログを残す\n",
    "    if epoch % 1000 == 0:\n",
    "        log = '誤差 = {:8.4f} ({:5d}エポック目)'\n",
    "        print(log.format(E(TY, TX), epoch))\n",
    "\n",
    "# 分類器\n",
    "def classify(X):\n",
    "    return (predict(X) > 0.8).astype(np.int)\n",
    "\n",
    "# テストデータ生成\n",
    "TEST_N = 1000\n",
    "testX = (np.random.rand(TEST_N, 2) * 1000).astype(np.int32) + 1\n",
    "testY = (testX.min(axis=1) / testX.max(axis=1) <= 0.2).astype(np.int)[np.newaxis].T\n",
    "\n",
    "# 精度計算\n",
    "accuracy = (classify(standardize(testX)) == testY).sum() / TEST_N\n",
    "print('精度: {}%'.format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
